{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11065806,"sourceType":"datasetVersion","datasetId":6895416}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -m venv venv && source venv/bin/activate\npip install --upgrade pip\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # cope cuda \npip install monai[nib] nibabel numpy scikit-image tqdm matplotlib albumentations pytorch-lightning\npip install gradio  # present","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T02:42:35.515450Z","iopub.execute_input":"2025-08-14T02:42:35.515711Z","iopub.status.idle":"2025-08-14T02:42:35.524396Z","shell.execute_reply.started":"2025-08-14T02:42:35.515693Z","shell.execute_reply":"2025-08-14T02:42:35.523201Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_36/3093708394.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install --upgrade pip\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3093708394.py, line 2)","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/USERNAME/REPO_NAME.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# train.py","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\nimport numpy as np\nimport torch\nfrom monai.data import CacheDataset, DataLoader, decollate_batch\nfrom monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd, ScaleIntensityRanged,\n    RandCropByPosNegLabeld, RandFlipd, RandRotate90d, ToTensord\n)\nfrom monai.networks.nets import UNet\nfrom monai.losses import DiceLoss\nfrom monai.metrics import DiceMetric\nfrom monai.inferers import sliding_window_inference\nfrom monai.apps import download_and_extract","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# -------- CONFIG ----------","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/aortic-seg\"  \n# data structure:\n# data/\n#   images/\n#   masks/\nimages = sorted(glob(os.path.join(data_dir, \"images\", \"*.nii*\")))\nmasks  = sorted(glob(os.path.join(data_dir, \"masks\",  \"*.nii*\")))\n\n# organization as images\nassert len(images) == len(masks)\n\n# individed\nn = len(images)\ntrain_ids = list(range(0, int(0.7*n)))\nval_ids   = list(range(int(0.7*n), int(0.85*n)))\ntest_ids  = list(range(int(0.85*n), n))\n\ndef make_pairs(ids):\n    return [{\"image\": images[i], \"label\": masks[i]} for i in ids]\n\ntrain_files = make_pairs(train_ids)\nval_files   = make_pairs(val_ids)\ntest_files  = make_pairs(test_ids)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# -------- TRANSFORMS ----------","metadata":{}},{"cell_type":"code","source":"train_transforms = [\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0,1.0,1.0), mode=(\"bilinear\",\"nearest\")),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=1000, b_min=0.0, b_max=1.0, clip=True),\n    RandCropByPosNegLabeld(\n        keys=[\"image\",\"label\"], label_key=\"label\",\n        spatial_size=(128,128,64), pos=1, neg=1, num_samples=4\n    ),\n    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=0),\n    RandRotate90d(keys=[\"image\",\"label\"], prob=0.5, max_k=3),\n    ToTensord(keys=[\"image\",\"label\"])\n]\n\nval_transforms = [\n    LoadImaged(keys=[\"image\",\"label\"]),\n    EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0,1.0,1.0), mode=(\"bilinear\",\"nearest\")),\n    Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n    ScaleIntensityRanged(keys=[\"image\"], a_min=-1000, a_max=1000, b_min=0.0, b_max=1.0, clip=True),\n    ToTensord(keys=[\"image\",\"label\"])\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# -------- DATASETS ----------","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = UNet(\n    spatial_dims=3,\n    in_channels=1,\n    out_channels=1,\n    channels=(16,32,64,128),\n    strides=(2,2,2),\n    num_res_units=2,\n).to(device)\n\nloss_function = DiceLoss(sigmoid=True)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ndice_metric = DiceMetric(include_background=False, reduction=\"mean\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# -------- TRAIN LOOP ----------","metadata":{}},{"cell_type":"code","source":"max_epochs = 200\nbest_metric = -1\nsave_path = \"./best_model.pth\"\n\nfor epoch in range(max_epochs):\n    model.train()\n    epoch_loss = 0\n    step = 0\n    for batch_data in train_loader:\n        step += 1\n        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    epoch_loss /= step","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VALIDATION (quick)","metadata":{}},{"cell_type":"code","source":"model.eval()\n    with torch.no_grad():\n        val_dice = []\n        for val_data in val_loader:\n            val_inputs, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n            val_outputs = sliding_window_inference(val_inputs, (128,128,64), 4, model, overlap=0.5)\n            val_outputs = torch.sigmoid(val_outputs)\n            val_outputs = (val_outputs > 0.5).float()\n            # compute dice\n            dice = dice_metric(y_pred=val_outputs, y=val_labels)\n            val_dice.append(dice.item())\n        mean_dice = np.mean(val_dice)\n\n    print(f\"Epoch {epoch+1}/{max_epochs} loss: {epoch_loss:.4f} val_dice: {mean_dice:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# save best","metadata":{}},{"cell_type":"code","source":"    if mean_dice > best_metric:\n        best_metric = mean_dice\n        torch.save(model.state_dict(), save_path)\n        print(f\"Saved new best: {best_metric:.4f}\")\n\nprint(\"Training finished.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}